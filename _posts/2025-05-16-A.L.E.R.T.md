---
layout: post
title:  "A.L.E.R.T"
summary: "A boomer shooter built using a custom game engine for the PlayStation 5"
date: '2025-05-16 00:00:00 +0000'
role: Engine Developer
team: ['Ryan Harland', 'Mathew France', 'Bradley Green', 'Claire Langton-Goh', 'Josh Wade', 'Austin Kurnia']
technologies: ['C++', 'Bespoke Engine', 'PlayStation 5', 'C#', 'ImGui', 'WPF', 'RapidJSON', 'tinyOBJ', 'fmt']
thumbnail: /assets/img/posts/A.L.E.R.T.png
permalink: /projects/A.L.E.R.T/
visibility: true
hidden-from-recents: false
featured: true
---

### Key Responsibilities
- Responsible for managing the workload of the other programmers on the team
- Implemented an asset hot reload system
- Implemented Sony Audio support
- Implemented Haptic Feedback
- Implemented a scene editor
- Implemented the rendering backend
- Implemented an OOP-based component system
- Implemented an ad-hoc reflection system for component discovery
- Implemented a deserialization and serialization system
- Implemented a series of compile time property helpers for gameplay programmers to expose internals to ImGui
- Implemented numerous gameplay components
- Implemented GitHub Actions to manage documentation generation
- Implemented a runtime logging system that logs gameplay events to the host system
- Implemented a prefab system
- Designed the tutorial and intermediary levels
- Designed and implemented a focusable GUI system with controller support
  - This also employed the use of the builder pattern to build GUI layouts from code

*This project, due to it's complex nature and number of working parts is described in some detail. For convenience a summary can be found just below*

### Project Summary


### Project Development Cycle
This project moved very quickly, due to only having 12 weeks. This meant prioritising engine features was a must. Going into the project
the engine wasn't very fleshed out at all, only being capable of loading data driven models and textures, as well as being able to spawn objects and move them around. Other basic features such as using ImGuizmo and scene management were included as well for designer utility. ImGuizmo was a particular challenge to integrate, due to the usage of needing to manually upgrade a special WIP version of ImGui.

![The engine's starting phase](/assets/img/posts/ALERT/engine-beginnings.png)
<p style="font-size: 13px; text-align: center;"><i>The humble beginnings of the engine, it had the ability to load and place models through the scene</i></p>

As you can see, this is nowhere remotely near anything suitable to build a game, so the most important things were tackled first. Firstly, working on external hardware meant
that some form of hot reload would become critical for iteration speed. It was for this reason a series of "manifest files" were created. At it's core, these were simply a collection of relative file paths that the engine would iterate, sanitize, validate and load. It would also use these paths to generate an assetname, which would be critical in referencing assets from elsewhere. 

To perform hot reloading the engine performs a sort of diff between manifests, firstly skipping any assets that appear both as loaded and still in the manifest. Secondly the engine checks if any loaded assets are no longer in the manifest (signifying deletion) and thus should be marked as dirty. Finally, the engine checks for any assets in the manifest that aren't loaded (signifying addition) and promptly loads them from the host machine.

To accompany the manifest files a secondary app was created in WPF following the MVVM design pattern. As editing text files is tedious, and invites the possibility of error, the WPF app ensure only assets of the correct type can be selected from Windows Explorer, and subsequently automatically generates the manifest files in the correct place, automatically locating the root of the project based on a specific "marker" file which it searches upwards for. 

The manifest generator also comes with some QOL features, namely being able to see the file size of the converted assets which can be a good indication of their final cost, handling conversion to the PlayStation specific formats, as well as providing thumbnail discovery to provide asset previews. Early editions also included a rudimentary data-only level editor, however as the component system was introduced this became too much technical debt to maintain two scene representations.

![The manifest generator tool](/assets/img/posts/ALERT/manifest-generator.png)
<p style="font-size: 13px; text-align: center;"><i>The manifest generator, showing all textures the engine will load, with pngs discovered for thumbnails</i></p>

Following this development sped up dramatically. I was responsible for implementing a component system. This featured a macro based reflection system for registering components and being able to clone their default objects, similar to how Unreal Engine handles things but nowhere near as complex or in-depth. This component was also critical to the JSON serialization and deserialization that was implemented (coincidentally also what allowed the scene editor in the WPF tool to work seamlessly at the start). 

This project made use of [RapidJSON](https://rapidjson.org/) to load and save JSON information, but to prevent lengthy serialization functions and to handle the engine's aggregate types such as vectors, a helper library was implemented to make loading a property as simple as `LOAD_PROPERTY('property_name', type, value);`. In order to enforce the gameplay interface to conform to the same controls as the engine's core interface, another helper library was similarly created to faciliate this, turning property exposure to a simple `imguiProperty<type>(&property, 'User Facing Name', propertyUUID);`.

![The component system](/assets/img/posts/ALERT/component-system.png)
<p style="font-size: 13px; text-align: center;"><i>The component system added to the game engine. This would allow for easy addition of behaviour, Unity style</i></p>

With core engine features implemented progress advanced rapidly. While a fellow team member worked on collision, I worked on getting some more features in such as a basic Blinn-Phong lighting model, the runtime lightweight log system, prefabs, 2D sprites, as well as getting the internal doxygen wiki up and automatically generating. With these features in and working it marked the end of the project's first milestone, and the engine was finally in a place where designers could use it and begin blocking out their levels.

![The engine at the end of milestone 1](/assets/img/posts/ALERT/milestone-1.png)
<p style="font-size: 13px; text-align: center;"><i>The engine by the end of milestone 1, with all aforementioned features</i></p>

Similarly to the first milestone, the second milestone brought much rapid development to the project. With gameplay features on the near horizon it became crucial to start focusing on designer feedback, designer utility, as well as more gameplay oriented features such as GUI and audio. The GUI system was one that must be made from scratch. By this point ImGui was taking a good few milliseconds of frametime away because of it's immediate nature, so it became necessary to make a custom system. 

Styling ImGui to have a transparent window or compiling an off the shelf game GUI system for the PS5 would have been far too time consuming as, much like with physics libraries I investigated, such things tend to become tangled in dependencies of dependencies. 

GUI was simple, we needed only 3 element types to begin, and could revisit the rest later. The core elements were progress bars, animated sprites and sprites. These were surprisingly simple to create. For progress bars it was merely a question of calculating the end vertex positions and properly interpolating the UV co-ordinates based on information passed into it's vertex shader. 

The nature of GUI also let us use a dummy buffer of vertices and pass in the actual verts through a buffer bound to the shader. This kept things cheap and ensured we would avoid any frame-in-flight issues that occured when doing it other ways. After this it was just a matter of creating the concept of scenes which contain multiple layers that occlude each other, and then hooking that into the existing scene system. Layouts are computed at initialization, preventing the need for xml files or heavy saving and loading that would certainly bloat engine size.

![The GUI system](/assets/img/posts/ALERT/gui.png)
<p style="font-size: 13px; text-align: center;"><i>The GUI system, with the animated weapon sprite, the health and shield bars and the ammo bar</i></p>

The rest of this milestone involved much smaller features such as working with the PlayStation specific audio API, implementing another render pass for debug wireframes, implementing scene specific game settings (such as player health, ammo count, shield amount, key counts, etc.), as well as smaller features such as snapping and UV scale options which were useful for level assembly. 

These features made the engine much more usable from a designer standpoint, and brought the engine one step closer to what people were used to commercially. The debug wireframes were especially useful, as this let us visualise the direction and bounds of light components, as well as the influence and volume taken up by collision components, which was especially important for making level triggers and pickups.

![The engine by the end of milestone 2](/assets/img/posts/ALERT/milestone-2.png)
<p style="font-size: 13px; text-align: center;"><i>The engine with more creature comforts, and the beginnings of the tutorial being blocked out</i></p>



